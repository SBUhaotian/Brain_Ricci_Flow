{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BmYIJOsj3LLU"
   },
   "source": [
    "Package Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gtTCgixv3QCR"
   },
   "outputs": [],
   "source": [
    "! pip install --upgrade numpy==1.21.1\n",
    "! pip install --upgrade GraphricciCurvature\n",
    "! pip install pycocotools==2.0.0\n",
    "! pip3 install pickle5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FEKe9G8o2HI0"
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import math\n",
    "import importlib\n",
    "import csv\n",
    "import glob\n",
    "import sys,pprint\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# import pickle5 as pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from GraphRicciCurvature.OllivierRicci import OllivierRicci\n",
    "from GraphRicciCurvature.FormanRicci import FormanRicci\n",
    "\n",
    "import networkx.algorithms.community as nx_comm\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i1HSWjP_3Shq"
   },
   "source": [
    "Function to run ricci flow with multiple rounds.\n",
    "\n",
    "Here, OllivierRicci is applied. In each round, we choose the subgraph with the most nodes and try to separate this subgraph into several communities structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "xek75zUn2KNJ"
   },
   "outputs": [],
   "source": [
    "def deep_ricci_flow(G, ori_G, rest_cluster):\n",
    "    if (rest_cluster == None):\n",
    "        rest_cluster = []\n",
    "\n",
    "    if (G.number_of_nodes() < 10):\n",
    "        return G\n",
    "\n",
    "    community = nx.connected_components(G)\n",
    "    origin_cluster = [list(c) for c in sorted(nx.connected_components(G), key=len, reverse=True)]\n",
    "    for i in range(len(rest_cluster)):\n",
    "        origin_cluster.append(rest_cluster[i])\n",
    "    origin_modularity = nx_comm.modularity(ori_G, origin_cluster)\n",
    "\n",
    "\n",
    "    cur_G = G.copy()\n",
    "    edge_weight = []\n",
    "    num_edge = len(G.edges)\n",
    "    orc = OllivierRicci(cur_G, alpha=0.5, verbose=\"ERROR\", nbr_topk=20)\n",
    "    orc.compute_ricci_flow(iterations=15)\n",
    "    cur_G = orc.G.copy()\n",
    "\n",
    "    G = cur_G.copy()\n",
    "    for pair in cur_G.edges:\n",
    "        edge_weight.append([pair, cur_G[pair[0]][pair[1]]['weight']])\n",
    "    \n",
    "    edge_weight = sorted(edge_weight, key=lambda x:x[1], reverse=True)\n",
    "\n",
    "    j = 0\n",
    "    gap = int(num_edge*0.05)\n",
    "    best_modularity = origin_modularity\n",
    "    best_G = cur_G.copy()\n",
    "    flag_reduced = False\n",
    "    cur_num_cluster = 1\n",
    "    while (j < int(num_edge*0.6)):\n",
    "        j += 1\n",
    "        cur_community = nx.connected_components(G)\n",
    "        cur_cluster = [list(c) for c in sorted(nx.connected_components(G), key=len, reverse=True)]\n",
    "\n",
    "        if (len(cur_cluster) == cur_num_cluster):\n",
    "            G.remove_edge(edge_weight[j][0][0], edge_weight[j][0][1])\n",
    "            continue\n",
    "        else:\n",
    "            cur_num_cluster = len(cur_cluster)\n",
    "            for i in range(len(rest_cluster)):\n",
    "                cur_cluster.append(rest_cluster[i])\n",
    "            # cur_cluster = cur_cluster + rest_cluster\n",
    "            cur_modularity = nx_comm.modularity(ori_G, cur_cluster)\n",
    "\n",
    "            if (cur_modularity > best_modularity):\n",
    "                best_modularity = cur_modularity\n",
    "                best_G = G.copy()\n",
    "\n",
    "            \n",
    "            # print(\"update: \", cur_cluster, best_modularity)\n",
    "        \n",
    "        if (j / gap == 4) and (len(cur_cluster) == 1):\n",
    "            best_G = G.copy()\n",
    "            flag_reduced = True\n",
    "\n",
    "        G.remove_edge(edge_weight[j][0][0], edge_weight[j][0][1])\n",
    "    \n",
    "    best_community = nx.connected_components(best_G)\n",
    "    best_cluster = [list(c) for c in sorted(best_community, key=len, reverse=True)]\n",
    "    complete_cluster = [list(c) for c in sorted(nx.connected_components(best_G), key=len, reverse=True)]\n",
    "    for i in range(len(rest_cluster)):\n",
    "        complete_cluster.append(rest_cluster[i])\n",
    "    # print(\"Complete: \", len(complete_cluster))\n",
    "    if (len(best_cluster) == 1) and (flag_reduced == False):\n",
    "        return G\n",
    "    else:\n",
    "        new_G = nx.Graph()\n",
    "        for c in best_cluster:\n",
    "            # print(\"iteration: \", len(c))\n",
    "            temp_cluster = []\n",
    "            for i in range(len(complete_cluster)):\n",
    "                if (complete_cluster[i] != c):\n",
    "                    temp_cluster.append(complete_cluster[i])\n",
    "            new_sub_G = ori_G.subgraph(c).copy()\n",
    "            # new_ori_G = ori_G.subgraph(c).copy()\n",
    "            new_G = nx.union(new_G, deep_ricci_flow(new_sub_G, ori_G, temp_cluster))\n",
    "        return new_G "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GskVEb-33tlX"
   },
   "source": [
    "Read the graph files which are Gpickle files.\n",
    "\n",
    "To compare with the ground truth, we use the modularity to visualize our performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c_O_UB0r2V9G"
   },
   "outputs": [],
   "source": [
    "path = \"/content/gdrive/MyDrive/Brain_Best_Run_Dataset/SyntheticGpickle/\"\n",
    "files = os.listdir(path)\n",
    "\n",
    "import pickle5 as pickle\n",
    "\n",
    "for file in files:\n",
    "    with open(path+file, \"rb\") as f:\n",
    "        G = pickle.load(f)\n",
    "    print(nx.info(G))\n",
    "    name = file \n",
    "    row = list(ground_truth['Unnamed: 0']).index(name)\n",
    "    gt_com_num = max((list(ground_truth.loc[row]))[1:])\n",
    "    gt_com_list = [[] for _ in range (gt_com_num)]\n",
    "    for i in range(1088):\n",
    "        gt_com_list[ground_truth.loc[row][i+1]-1].append(i)\n",
    "    ground_truth_list = [0 for _ in range(1088)]\n",
    "    for i in range(1088):\n",
    "        ground_truth_list[i] = ground_truth.loc[row][i+1]\n",
    "\n",
    "    gt_mod = (nx_comm.modularity(G, gt_com_list))\n",
    "    print(\"Modularity of ground truth graph: \", gt_mod) \n",
    "\n",
    "    ori_G = G.copy()\n",
    "\n",
    "    G = deep_ricci_flow(G, ori_G, [])\n",
    "\n",
    "    community = nx.connected_components(G)\n",
    "    cluster = [list(c) for c in community]\n",
    "    print(\"Final: \", len(cluster))\n",
    "    print(nx_comm.modularity(ori_G, cluster))\n",
    "    print(nx.info(G))\n",
    "\n",
    "    community_index = [0 for _ in range(1088)]\n",
    "    for i in range(len(cluster)):\n",
    "        for j in cluster[i]:\n",
    "            community_index[j] = i\n",
    "    \n",
    "    print(\"ARI: \", adjusted_rand_score(ground_truth_list, community_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4TdIeG4f5eqr"
   },
   "source": [
    "Store graph file in .mat file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eYT36cuh5dxO"
   },
   "outputs": [],
   "source": [
    "path = \"\"\n",
    "mat_path = \"\"\n",
    "\n",
    "files = os.listdir(path)\n",
    "\n",
    "for file in files:\n",
    "    name = file[0:8]\n",
    "    print(path+file)\n",
    "    G = nx.read_gpickle(path + file)\n",
    "    print(nx.info(G))\n",
    "    break\n",
    "\n",
    "    cur_com = [G.subgraph(c).copy() for c in nx.connected_components(G)]\n",
    "    cur_com = sorted(cur_com, key = lambda x: len(x), reverse = True)\n",
    "\n",
    "    k = len(cur_com)\n",
    "    member_community = [[0 for _ in range(1088)] for _ in range(k)]\n",
    "\n",
    "    for i in range(k):\n",
    "        for j in range(len(cur_com[i])):\n",
    "            print(cur_com[i])\n",
    "            member_community[i][cur_com[i][j]] = 1\n",
    "\n",
    "    sio.savemat(mat_path + name + '_cluster' + '.mat', {'com_members': member_community})"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Automatical_Ricci_Flow.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
